\appendixpageoff
\begin{appendices}

\chapter{Abbreviations}
We enclose a list of abbreviations with the meaning they represent.
\begin{description}
    \item[1D] one dimensional
\item[2D] two dimensional
\item[ANN] artificial neural network
\item[AC] action creator
\item[AcF] activation function
\item[BE] back-end application
\item[CCross] categorical crossentropy
\item[CNN] convolutional neural network
\item[CSS] Cascading Style Sheets
\item[CSV] comma-separated values
\item[ConvL] convolutional layer
\item[ConvO] convolution operation
\item[DD] drop-down button
\item[DnsL] dense layer
\item[DRF] Django REST framework
\item[ES] Elasticsearch
\item[EmbL] embedding layer
\item[FE] front-end application
\item[HTML] Hypertext Markup Language
\item[I2P] The Invisible Internet Project
\item[id] identificator
\item[JS] JavaScript
\item[LA] Louvain algorithm
\item[LeA] Leiden algorithm
\item[LsF] loss function
\item[ML] machine learning
\item[NLTK] Natural Language Toolkit
\item[OHV] one hot vector
\item[ORing] onion routing
\item[PoolL] pooling layer
\item[RD3] the react-d3-graph library
\item[REST] representational state transfer
\item[RLr] reinforcement learning
\item[ReLU] rectified linear unit
\item[React] React.js
\item[Redux] Redux.js
\item[SLr] supervised learning
\item[SSK] symmetric session key
\item[TS] TypeScript
\item[Tor] The Onion Router
\item[UI] user interface
\item[ULr] unsupervised learning
\item[XLS] excel spreadsheet
\item[back-prop] backward propagation of error
\item[batch cycle] is a typical learning cycle over a mini-batch  in a ANN using SLr
\item[cluster cycle] is one iteration of community detection
\item[community-node] is a community considered a node in the detection of communities in the LA or the LeA
\item[decomposable community] is a community with no more than 30 members. It can be decomposed so that the members are displayed. Communities where zooming is possible are also called decomposable.
\item[enhanced samples] are the second learning data set based on first samples with enhanced \textit{Gambling} and 10 categories
\item[final samples] are the third and final learning data set based on enhanced samples with 9 categories
\item[first samples] are the learning first data set containing 14 categories
\item[igraph] the python-igraph library
\item[max count] it the maximum desired number of communities to be returned by the API
\item[naive approach] is a simple classification system with a list of words assigned to each category introduced in Subsection~\ref{naiveApproach}
\item[old-link] are links of nodes belonging to the same community-node in the detection of communities in the LA or the LeA
\item[pickle] Python pickle module
\item[shelve] Python module shelve
\end{description}

\chapter{Data attachment}
The attachments enclosed in the thesis repository\footnote{https://is.muni.cz/auth/th/noh49/} contain three projects with dumps. The files have the following structure.
\begin{description}
    \item[\textbf{\texttt{Categorization}}] contains the source code for the sample data set acquisition and the classification of the manually labeled learning set. The labeled learning set without pages labeled as \textit{Sexual content} is also included. The pages of \textit{Sexual content} were removed because of moral and legal issues. In case of interest contact RNDr. Martin StehlÃ­k, Ph.D. 
    \item [\texttt{Dark-web-categorization-BE}] encompasses the source code of the BE application with the API. The \textit{Redis} and \textit{shelve} dumps are also present.
    \item [\texttt{Dark-web-categorization}] holds the source code to the FE application. 
\end{description}



\chapter{Train a classification model}
In order to to train a classification model, the following prerequisites need to be installed.
\begin{description}
    \item[Python 3] \hfill
    \item[Pip 3] \hfill
        \begin{itemize}
	 \item \texttt{sudo apt update}
            \item \texttt{apt-get install python3-pip}
        \end{itemize}
\end{description}
We now describe the steps to run the classification process itself.
\begin{itemize}
    \item Download the \texttt{Categorization.zip} file and unpack it.
    \item \texttt{cd Categorization}
    \item \texttt{pip3 install -r requirements.txt}
    \item \texttt{jupyter-notebook}
    \item Open one of the listed url addresses in a browser.
    \item In the browser, open \texttt{keras\_classification\_model} in the \texttt{training} directory.
    \item From the header menu select \textit{Cell} > \textit{Run all}
    \item After the computation is finished the following files are dumped into the \texttt{models} directory.
        \begin{itemize}
            \item \texttt{DarkWebCategoryModel.h5}
            \item \texttt{DarkWebCategoryModel.json}
            \item \texttt{tokenizer.pickle}
        \end{itemize}
The output of the last cell contains the achieved accuracy,  a confusion matrix and the index--category lookup table. The index--category lookup table must also be stored if the newly trained model is to be used.
\end{itemize}



\chapter{Run the web application}
\section{Prerequisites} \label{dixAppPrerequisites}
In order to run the web application the following prerequisites need to be installed.
\begin{description}
    \item[Python 3] \hfill
    \item[Pip 3] \hfill 
        \begin{itemize}
	 \item \texttt{sudo apt update}
            \item \texttt{apt-get install python3-pip}
        \end{itemize}
    \item[Redis] \hfill 
        \begin{itemize}
            \item \texttt{sudo apt-get install redis-server}
        \end{itemize}
    \item[Npm 6.4.1 and Node.js 10.14.1] as we cannot guarantee our application to function correctly with different versions of Npm and Node.js
        \begin{itemize}
            \item \texttt{sudo apt install node}
            \item \texttt{sudo apt install npm 6.4.1}
            \item \texttt{npm install -g n}
            \item \texttt{node n 10.14.1}
        \end{itemize}
\end{description}

\section{Back-end}
We describe how to run the BE on a Ubuntu system.
\begin{itemize}
    \item Download the \texttt{Dark-web-categorization-BE.zip} file and unpack it.
    \item \texttt{cd Dark-web-categorization-BE}
    \item \texttt{pip3 install -r requirements.txt}
    \item \texttt{redis-server} This command needs to be executed from the root directory \texttt{Dark-web-categorization-BE}.
    \item \texttt{python manage.py runserver 0.0.0.0:8000}
\end{itemize}
To use new dumped classification files move them into the \texttt{models} directory located in the \texttt{Dark-web-categorization-BE} root directory. The index-category lookup table needs to replace the table in \texttt{Dark-web-categorization-BE/api/classification.py}.

\section{Front-end}
We describe how to run the FE on Ubuntu systems.
\begin{itemize}
    \item Download the \texttt{Dark-web-categorization.zip} file and unpack it.
    \item \texttt{cd Dark-web-categorization}
    \item \texttt{npm install --no-optional}
    \item \texttt{npm run start}
\end{itemize}


\chapter{Classification results}
We detail the statistical values of the accuracy results of the trained models described in Section \ref{classificationEvaluation}.

\begin{table}[ht!]
\centering
\scalebox{0.95}{
\begin{tabular}{c|cccccc}
 \toprule
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Plot\\\rowcolor[HTML]{EEF9FB}  values\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Upper\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 3rd \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{Median}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 1st \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Lower\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{Mean}} \\ 
 \midrule
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C1}} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C2}} & {\color[HTML]{000000} 72.41} & {\color[HTML]{000000} 70.83} & {\color[HTML]{000000} 59.74} & {\color[HTML]{000000} 46.67} & {\color[HTML]{000000} 40.00} & {\color[HTML]{000000} 57.59} \\
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C3}} & {\color[HTML]{000000} 100.00} & {\color[HTML]{000000} 76.92} & {\color[HTML]{000000} 70.84} & {\color[HTML]{000000} 58.33} & {\color[HTML]{000000} 10.00} & {\color[HTML]{000000} 66.43} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C4}} & {\color[HTML]{000000} 33.33} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 5.00} \\
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C5}} & {\color[HTML]{000000} 91.67} & {\color[HTML]{000000} 61.54} & {\color[HTML]{000000} 51.92} & {\color[HTML]{000000} 33.33} & {\color[HTML]{000000} 22.22} & {\color[HTML]{000000} 50.66} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C6}} & {\color[HTML]{000000} 97.30} & {\color[HTML]{000000} 95.89} & {\color[HTML]{000000} 93.46} & {\color[HTML]{000000} 90.71} & {\color[HTML]{000000} 65.10} & {\color[HTML]{000000} 90.70} \\
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C7}} & {\color[HTML]{000000} 100.00} & {\color[HTML]{000000} 66.67} & {\color[HTML]{000000} 58.34} & {\color[HTML]{000000} 20.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 49.00} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C8}} & {\color[HTML]{000000} 50.00} & {\color[HTML]{000000} 50.00} & {\color[HTML]{000000} 39.28} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 0.00} & {\color[HTML]{000000} 27.86} \\
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C9}} & {\color[HTML]{000000} 88.76} & {\color[HTML]{000000} 83.75} & {\color[HTML]{000000} 78.33} & {\color[HTML]{000000} 73.49} & {\color[HTML]{000000} 53.01} & {\color[HTML]{000000} 75.52} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C10}} & {\color[HTML]{000000} 74.29} & {\color[HTML]{000000} 70.00} & {\color[HTML]{000000} 67.82} & {\color[HTML]{000000} 58.06} & {\color[HTML]{000000} 33.33} & {\color[HTML]{000000} 62.82} \\
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C11}} & {\color[HTML]{000000} 92.26} & {\color[HTML]{000000} 90.73} & {\color[HTML]{000000} 88.54} & {\color[HTML]{000000} 85.21} & {\color[HTML]{000000} 80.00} & {\color[HTML]{000000} 87.84} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C12}} & {\color[HTML]{000000} 97.21} & {\color[HTML]{000000} 96.30} & {\color[HTML]{000000} 95.10} & {\color[HTML]{000000} 92.99} & {\color[HTML]{000000} 91.75} & {\color[HTML]{000000} 94.69} \\
\rowcolor[HTML]{DAE8E5} 
{\color[HTML]{000000} \textbf{C13}} & {\color[HTML]{000000} 47.06} & {\color[HTML]{000000} 34.78} & {\color[HTML]{000000} 34.05} & {\color[HTML]{000000} 30.43} & {\color[HTML]{000000} 21.05} & {\color[HTML]{000000} 33.58} \\
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{C14}} & {\color[HTML]{000000} 93.97} & {\color[HTML]{000000} 91.38} & {\color[HTML]{000000} 86.27} & {\color[HTML]{000000} 85.34} & {\color[HTML]{000000} 81.73} & {\color[HTML]{000000} 87.54} \\
\bottomrule
\end{tabular}
}
\caption{The statistical values of training on the first samples. The visualization is shown in Figure \ref{CM1Boxplot}.}
\label{CM1BoxplotValues}
\end{table}

\begin{table}[h]
\centering
\scalebox{0.95}{
\begin{tabular}{@{}c|cccccc@{}}
 \toprule
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Plot\\\rowcolor[HTML]{EEF9FB}  values\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Upper\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 3rd \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{Median}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 1st \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Lower\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{Mean}} \\ 
\midrule
\rowcolor[HTML]{DAE8E5} 
\textbf{C2} & 97.31 & 94.97 & 94.47 & 93.20 & 90.40 & 94.09 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C6} & 96.60 & 95.97 & 92.59 & 91.45 & 68.57 & 91.00 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C7} & 98.08 & 97.87 & 97.47 & 91.67 & 89.58 & 95.12 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C9} & 98.80 & 89.74 & 82.57 & 78.31 & 71.05 & 84.07 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C15} & 86.84 & 66.67 & 63.82 & 43.33 & 30.56 & 60.13 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C10} & 76.67 & 71.43 & 65.97 & 52.94 & 45.16 & 63.08 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C11} & 94.34 & 90.00 & 86.94 & 82.24 & 54.04 & 84.00 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C12} & 69.81 & 68.18 & 66.37 & 60.71 & 57.14 & 64.72 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C13} & 65.22 & 42.86 & 29.48 & 17.24 & 2.86 & 30.29 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C14} & 95.33 & 89.08 & 87.77 & 84.82 & 80.19 & 87.63 \\
\bottomrule
\end{tabular}
}
\caption{The statistical values of training on the enhanced samples.  The visualization is portrayed in Figure \ref{CM2Boxplot}.}
\label{CM2BoxplotValues}
\end{table}

\begin{table}[]
\centering
\scalebox{0.95}{
\begin{tabular}{@{}c|cccccc@{}}
 \toprule
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Plot\\\rowcolor[HTML]{EEF9FB}  values\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Upper\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 3rd \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{Median}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 1st \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Lower\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{Mean}} \\ 
\midrule
\rowcolor[HTML]{DAE8E5} 
\textbf{C6} & 95.77 & 94.66 & 90.47 & 90.00 & 86.92 & 91.38 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C7} & 100.00 & 96.00 & 95.29 & 92.68 & 75.56 & 93.26 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C8} & 92.86 & 80.68 & 73.37 & 64.04 & 46.67 & 72.02 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C9} & 88.89 & 84.21 & 75.12 & 65.38 & 46.43 & 73.05 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C10} & 77.27 & 70.97 & 68.20 & 65.00 & 58.82 & 68.18 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C11} & 92.31 & 88.03 & 86.18 & 85.44 & 78.12 & 86.19 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C16} & 98.36 & 96.86 & 96.63 & 95.80 & 94.44 & 96.50 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C13} & 62.07 & 40.74 & 35.71 & 30.00 & 13.79 & 36.49 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C14} & 94.12 & 92.44 & 88.69 & 84.96 & 83.61 & 88.63 \\
\bottomrule
\end{tabular}
}
\caption{The statistical accuracy values of training on the final samples. The portrayal is depicted in Figure \ref{CM3Boxplot}.}
\label{CM3BoxplotValues}
\end{table}

\begin{table}[]
\centering
\scalebox{0.95}{
\begin{tabular}{@{}c|cccccc@{}}
 \toprule
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Plot\\\rowcolor[HTML]{EEF9FB}  values\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Upper\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 3rd \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{Median}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 1st \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Lower\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{Mean}} \\ 
\midrule
\rowcolor[HTML]{DAE8E5} 
\textbf{C6} & 97.97 & 96.00 & 94.13 & 92.09 & 86.15 & 93.70 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C7} & 98.15 & 97.44 & 96.11 & 94.87 & 90.48 & 95.72 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C8} & 98.63 & 85.71 & 75.45 & 57.97 & 42.31 & 72.44 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C9} & 88.89 & 83.33 & 64.87 & 50.00 & 8.33 & 60.95 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C10} & 82.35 & 75.00 & 66.89 & 58.62 & 32.00 & 64.49 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C11} & 90.45 & 88.16 & 86.01 & 81.37 & 27.11 & 80.02 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C16} & 98.71 & 97.24 & 96.74 & 96.54 & 92.53 & 96.36 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{C13} & 68.42 & 58.06 & 45.86 & 37.04 & 0.00 & 44.17 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{C14} & 93.75 & 89.86 & 86.76 & 84.68 & 75.86 & 86.74 \\
\bottomrule
\end{tabular}
}
\caption{The statistical accuracy values of training on the final samples with pretrained embeddings. The visualization is shown in Figure \ref{CM3EmbeddingsBoxplot}.}
\label{CM3EmbeddingsBoxplotValues}
\end{table}

\begin{table}[]
\centering
\scalebox{0.83}{
\begin{tabular}{@{}c|cccccc@{}}
 \toprule
\rowcolor[HTML]{EEF9FB} 
{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Plot\\\rowcolor[HTML]{EEF9FB}  values\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Upper\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 3rd \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{Median}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} 1st \\ \rowcolor[HTML]{EEF9FB} quartile\end{tabular}}} & {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}\rowcolor[HTML]{EEF9FB} Lower\\ \rowcolor[HTML]{EEF9FB} whisker\end{tabular}}} & {\color[HTML]{000000} \textbf{Mean}} \\ 
\midrule
\rowcolor[HTML]{DAE8E5} 
\textbf{first samples} & 86.11 & 85.38 & 84.77 & 82.22 & 76.98 & 83.65 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{enhanced samples} & 86.69 & 85.76 & 85.01 & 81.25 & 77.78 & 83.81 \\
\rowcolor[HTML]{DAE8E5} 
\textbf{final samples} & 88.19 & 87.73 & 86.86 & 85.88 & 81.37 & 86.41 \\
\rowcolor[HTML]{EEF9FB} 
\textbf{final samples E} & 89.24 & 88.54 & 86.11 & 84.95 & 72.69 & 85.41 \\
\bottomrule
\end{tabular}
}
\caption{The statistical values of the overall accuracy of training on individual data sets. This is depicted in Figure \ref{DSsBoxplot}.}
\label{DSsBoxplotValues}
\end{table}


\chapter{Imeplementation details}
\section{Classification}
\subsection{Removing non-English documents} \label{dixRemoveNonEnglish}
The removal of non-English documents is achieved by first removing non-numeric and non-alphabetical characters. Then the content is tokenized\footnote{A tool which divides a string into sub-strings.}. In this case the tokens represent words divided by spaces. The tokens are then compared to the English vocabulary of NLTK. The document is considered English or non-English according to the percentage of the English words composing the content. The threshold of English documents is 20\%. This threshold was chosen after discussions with the supervisor. Non-English documents are removed from the data frame.

\subsection{Embedding vector} \label{dix_embeddingVector}
We enclose a portion of an embedding vector for the words \textit{email} copied from the embedding index of the embedding layer.

\texttt{array([\\
 -0.57792, -0.16606, -0.17226, -0.87941,  0.30588,\\
...,\\
  0.052887, 0.077703, -0.10182, -0.33831, 0.55555\\
], dtype=float32)}

\subsection{Vocabulary initialization}
We detail the initialization of the internal vocabulary. This step precedes the random division of the learning data into training and testing data described in Subsection \ref{ClassificationImplementation}. 

Each word $w$ of each entry in \texttt{texts} is represented by an integer $n_w$. An example of a portion of such a vocabulary is shown in Subsection \ref{DSvocabulary}. Each entry of \texttt{texts} therefore corresponds to a vector of integers. All vectors are trimmed or padded to the same length of 1,000 integers. 
\subsection{Data set vocabulary} \label{DSvocabulary}
We enclose a portion of the vocabulary created from our data set.

\texttt{
\{\\
\text{    }"1": "porn", "2": "porno", "3": "the", "4": "to", ...,\\
    ...,\\
    ..., "129988": "3e3zx2drxj", "129989":"tapasoth"\\
\}}

\section{API}
\subsection{Classification} \label{dixApClassification}
The class Categorizer first loads the tokenizer and the trained model. Then the model is compiled with the same attributes as described in Subsection \ref{ClassificationImplementation}. Both the tokenizer and the model are utilized in the method \texttt{categorize}. This method expects the page content as parameter. It applies the tokenizer to the received content. The output is padded or concatenated to the same length of 1,000 digits. The model predicts the category alias of the modified content. Lastly, the alias is converted to the name of the category.
\FloatBarrier 

\subsection{Models} \label{dixModels}
\begin{figure}[ht!]
  \centering
  \includegraphics[height=0.85\textheight]{Images/BEmodelsDiagram.png}
  \caption{A class diagram of the classes used in the BE. The diagram was created leveraging Visual Paradigm \cite{visualParadigm}}
  \label{BEmodelsDiagram}
\end{figure}
\FloatBarrier 

\subsection{Response example} \label{dixAPIResponse}
 We now detail an example of handeling a response. The API structure is described in Subsection \ref{APIImplementation}. Let us assume the API received the request 
\begin{quotation}
 \texttt{GET /api/pages/bylink/?content-type=json\&id=2.0}. 
\end{quotation}
The client now expects the API to return sub-communities of the community with the id \textit{2.0}. The ViewSet \texttt{GroupsByLinkViewSet} is assigned to the used endpoint. The method used in the request is \textit{GET}. Therefore the \textit{list} function of \texttt{GroupsByLinkViewSet} is called. The url provided contains the \texttt{id} parameter. The helper method \\ \texttt{get\_subgroups\_of\_group} with the provided \texttt{id} is called. 

The method caches and returns a list of \texttt{Group} objects. However, this response would be too sizable for the server-client communication. That is why the \texttt{Group} objects are converted to \texttt{Meta\_Group} objects. A \texttt{Meta\_Group} object does not contain all of the community members. It contains only the first 30 members as \texttt{Page} objects. \texttt{Meta\_Group} also contains an attribute representing the total number of the members. The list of \texttt{Meta\_Group} objects is serialized via the \texttt{MetaGroupSerializer}. 

At last a \texttt{Response} object is constructed with the serialized result as its data. The response is returned to the client.

\subsection{Page acquisition} \label{dixRepositories}
We detail the implementation of the different page acquisition methods.

Method \texttt{basic\_search} is used for the filtering of nodes based on page-content or page-ulr. 

Method \texttt{fetch\_chunk} retrieves portions with pages called \textit{chunks} from the database. In this thesis a chunk contains 500 pages. Each response from the database holds a chunk and a \textit{scroll\_id}. The scroll\_id is sent embedded in the next request to the database. The enclosed chunk in the next response from \textit{Elasticsearch}  depends on the scroll\_id. The search context of \textit{Elasticsearch} is kept open for 1 minute. This is defined by the \texttt{scroll} attribute. Each request extends this time by another minute. 

Method \texttt{fetch\_all} gets all pages from the database. Here the method \texttt{fetch\_chunk} is called repeatedly until the response carries no pages. Each chunk is converted into a dictionary of \texttt{Page} objects with the page url as key and the whole page as value. Also, each batch is stored on the disc in a \textit{shelf}. The keys in the \textit{shelf} are indexes of the batches and the values are the entire batches. After all the pages from the database are obtained the content is removed from the pages. Also, invalid links are deleted from the pages. Then the pages are cached in \textit{Redis}.

\section{FE}
\subsection{The remaining FE file structure}
\begin{description}
    \item[\texttt{node\_modules}] contains imported libraries including \textit{React}, \textit{Redux} or \textit{d3}.
    \item[\texttt{public}] encloses an \textit{.ico} file\footnote {A picture with the dimensions 16x16 pixels used by the browser to represent the web page or application. It is usually displayed in the tab in which the application is opened.} and an HTML file which is the default entry point when the application is started. 
    \item[\texttt{commont.d.ts}] holds types used heavily across the application, e.g. \textit{Action}. Types in this file are available without importing them to all files in the project.
\end{description}

\subsection{State modification structure explained}\label{dixModifyReduxState}
The most basic files which only include string constants are situated in the directories named \texttt{actionTypes}.  These are utilised as action types in actions. An action is a simple object containing a string type and an optional payload. Actions themselves are returned by action creators~(AC). 

ACs are functions returning actions and can be found in directories called \texttt{actions}. They can be as simple as those present in the file \texttt{nodesActionCreators.ts}. But they can be more complicated such as the ACs \texttt{fetchNodes.ts} and dispatch multiple simple ACs. The AC \texttt{fetchNodes} is described in more detail in Subsection \ref{dixComplicatedAC}. The purpose of an AC is to be injected into \hyperlink{reducers}{reducers}, i.e. dispatch \texttt{actions}. 

The dispatching of actions enables the changing of the state via reducers situated in the \texttt{reducers} directories. The state is a single immutabe\footnote{The object cannot be adjusted directly. Instead, a new modified object is returned and the original one stays unmodified.} object and is used in the entire application. A \hypertarget{reducers}{reducer} is a pure function\footnote{The return value of a pure function is only dependent on its input values. A pure function has no side effects.} receiving the current state and the dispatched action as its arguments. It then returns the newly computed state. A reducer builds a new state only if the type of the given action is recognized. If not, the previous state is returned unmodified. 

The state object received or returned by the reducer does not need to be the entire state (app-state). A reducer may be responsible for only a part of the app-state. However, the root reducer is responsible for the entire app-state.

\subsection{Detailed fetchNode AC}\label{dixComplicatedAC}
The AC \texttt{fetchNodes}, and the directory the AC is placed in share the same name. For easier testing purposes the main logic of this AC is put into a function which receives the simple ACs as dependencies. 

When this AC is called it first dispatches a simple AC to indicate the fetching has begun. After that an identificator (id) is initialized. This id is later used to create an error object in case of failure.

 Next, the fetching itself begins. The fetching in \texttt{fetchNodes} is realized with the library \textit{isomorphic-fetch}. The fetch function of this library expects the first argument to be the url address of the resource. The second argument is an object describing further details of the request and is optional. Such an object may contain the request method, headers or the payload. If the request does not result in error the response status is checked. 

After the fetching is complete a success AC with the acquired response is dispatched. If an error is caught during the fetching a failure AC is dispatched. The payload of this AC is an error-object with the id and error message if any.

\end{appendices}