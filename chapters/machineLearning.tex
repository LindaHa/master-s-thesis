\label{machineLearning}
A part of this thesis was the categorization of the scraped pages. Categorization in this context means the process of assigning categories (labels) to pages. The data set at hand contained a vast amount of pages, as we discussed in chapter \ref{datasetAnalysis}. The manual categorization of this number of pages would therefore take too much time and in consequence was infeasible. An automatic system for text classification was required. A simple system with a list of words assigned to each label was introduced but was performing poorly. A more sophisticated tool for text categorization is machine learning. We decided to use supervised machine learning (ML).

This chapter describes ML in general. Secondly, the main approaches of ML, reinforcement learning(RL), unsupervised learning (UL), and supervised learning (SL), are characterized. Lastly we depict what an artificial neural network (ANN) is. The approach used in this thesis is an ANN using SL.
 
\section{Machine learning} \label{machineLearning}
The term \textit{machine learning} was first introduced by Arthur Samuel. In his paper \textit{Some Studies in Machine Learning Using the Game of Checkers} \cite{machineLearningOriginal} he proved it is possible for a program to develop better game-related skills than the skills of the programmer of the program.

ML is the process in which an agent creates a model which develops the ability to perform a certain task at least as well as a human would. The learning process is based on the evaluation of gained experience \cite{machineLearningToday}. The agent requires an initial data set in order to train and validate. The size of initial the data set depends on the nature of the task and the selected ML type and set of algorithms. During training the agent attempts to perform the given task and validates its own performance. The agent then adjusts its criteria for performing the task based on the validation results. These two steps are repeated a number of times defined by the programmer. The output of the agent is a model able to perform the task it was trained for. 

ML is used across various industries and fields. The need for automated analysis is increasing with the growing popularity of \textit{big data}\footnote{A data set too vast or complex for traditional or manual data processing.} \cite{bigDataExplained} \cite{bigDataPopularity}. ML is used widely with Big Data. Another use for ML is in the automotive industry. Cars with assisted parking or breaking, or self-driving cars are examples\cite{selfDrivingCars}. Also, ML is used frequently in games for a more natural game experience \cite{machineLearningGaming}. 

There are several approaches in ML based on the different ways of training. We describe the three main approaches in the subsections following. Namely \textit{reinforcement learning} in subsection \ref{reinforcementLearning}, \textit{unsupervised learning} in subsection \ref{unsupervisedLearning}, and \textit{supervised learning} in subsection \ref{supervisedLearning}. The approach used in this thesis was \textit{supervised learning}. 

\subsection{Reinforcement learning} \label{reinforcementLearning}
It is suitable to use RL if behaviours in dynamic environments are to be learned \cite{reinforcementLearningIntroduction}. A software agent receives an indication of the state of the environment. The agent then pics an action from a discrete set of agent actions. Next the state is modified by the action. The value of this modification is passed on as a scalar reinforcement signal to the agent. The objective for the agent is to maximize the long-run total of reinforcement signal values. This is achieved over time by leveraging a number of specialized algorithms together with methodical trial and error.

\subsection{Unsupervised learning} \label{unsupervisedLearning}
 UL is used when seeking common patterns or relationships in data. It is also commonly used when trying to find anomalies in data. UL in context of ML is inspired by the neurons in our brains and the way our brains learn without external instructions \cite{unsupervisedLearningIntroduction}. The software agent receives an unlabeled data set as input. The agent breaks the data down to critical components using specialized algorithms. It then identifies similarities and divides the data into groups. No feedback is involved.

\subsection{Supervised learning} \label{supervisedLearning}
SL is suitable to use for the classification of data. During training SL relies on labeled data \cite{machineLeraningApproaches}. The input of the software agent of SL is a labeled data set. The software agent divides the data---label pairs into a a training and test set randomly. The agent is to find a function with the data as input and the correct label as output. To achieve this the agent is trained on the training set and validated using the test set. After each run the accuracy and loss is computed and the function is modified with the goal to improve the future output. 

\section{Artificial neural networks} \label{artificialNeuralNetworks}
An ANN is a ML system inspired by animal brains \cite{machineLeraningApproaches}. A brain is composed of components such as neurons. Neurons communicate with each other by passing information through synapses. The more often two neurons communicate the stronger the synapses between them are \cite{neuronsInBrain}. This results in a neuron prioritizing information passed by neurons participating in frequent communication. 

An ANN is comprised of layers of nodes sometimes also called \textit{neurons}. The neurons communicate via directed links of various relevance also called \textit{weight}. The weight is represented by a real number. A neuron determines whether to react to information gathered through a link according to its weight passed to an \textit{activation function}. We discuss activation functions later in subsection \ref{activationFunction}. Neurons exist in groups called \textit{layers}. Layers used in this thesis were \textit{convolutional layers} \ref{convolutionalLayers}, \textit{polling layers} \ref{poolingLayers}, and \textit{dense layers} \ref{denseLayers}. All of the used layers are described closer in the next subsections. 

One learning cycle is called an \textit{epoch}. The number of epochs is specified by the programmer. In this paragraph we characterize a typical epoch in an ANN using SL. At the beginning of an epoch the training data is passed to the first layer. Data is passed from one layer to the next one. Every layer modifies the received data before passing it on. The manner in which the data is modified depends on the type of the layer. After the data is processed by the last layer the output model is evaluated using the testing data. Improving the model is now the objective. A way leveraged to improve accuracy is the calculation of the loss by utilizing a \textit{loss function}. The loss function is outlined in more detail in subsection \ref{lossFunction}. After evaluating the loss the weights of the neurons are adjusted by the \textit{backward propagation of errors} detailed in subsection \ref{backpropagation}. After the weights of the first layer have been adjusted the epoch ends.


\subsection{Convolutional layer}\label{convolutionalLayers}
\subsection{Pooling layer}\label{poolingLayers}
\subsection{Dense layer}\label{denseLayers}
\subsection{Activation function}\label{activationFunction}
\subsection{Loss function}\label{lossFunction}
\subsection{Backward propagation of error}\label{backpropagation}
Backward propagation of error  (backpropagation)
\subsection{}\label{}
